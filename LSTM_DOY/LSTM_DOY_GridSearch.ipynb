{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "841b2ac1-b2ab-46a7-8098-7e511d1bbe05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "841b2ac1-b2ab-46a7-8098-7e511d1bbe05",
        "outputId": "e93a878b-f041-4a63-a3a2-416b6a619466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn==1.5.2 in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\n",
            "1.5.2\n",
            "Current time: 2025-06-25 21:46:12.864782\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import dataretrieval\n",
        "except ImportError:\n",
        "    print(\"dataretrieval not found. Installing...\")\n",
        "    !pip install dataretrieval\n",
        "    import dataretrieval # Import again after installation\n",
        "\n",
        "from dataretrieval import nwis # hydrological time-series data from USGS\n",
        "\n",
        "# Use scikit-learn to grid search the number of neurons\n",
        "import numpy as np\n",
        "\n",
        "!pip install scikit-learn==1.5.2 # TO AVOID AttributeError: 'super' object has no attribute '__sklearn_tags__'\n",
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV  #  hyperparameter tuning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "#!pip install scikeras\n",
        "#from scikeras.wrappers import KerasRegressor\n",
        "\n",
        "try:\n",
        "    from scikeras.wrappers import KerasRegressor\n",
        "except ImportError:\n",
        "    print(\"scikeras not found. Installing...\")\n",
        "    !pip install scikeras\n",
        "    from scikeras.wrappers import KerasRegressor\n",
        "\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score # Imports several common regression evaluation metrics from scikit-learn:\n",
        "from datetime import datetime\n",
        "# Get the current time\n",
        "current_time = datetime.now()\n",
        "# Print the current time\n",
        "print(\"Current time:\", current_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0c41c89c-ca94-4e5d-ab16-6dea19a694cf",
      "metadata": {
        "id": "0c41c89c-ca94-4e5d-ab16-6dea19a694cf"
      },
      "outputs": [],
      "source": [
        "startDate = \"1995-10-01\"\n",
        "endDate = \"2024-09-30\"\n",
        "model_site = [\n",
        "  \"13190500\"\n",
        "]\n",
        "\n",
        "units_day = 365\n",
        "#missing_data_threshold = 0.90 *365\n",
        "\n",
        "summer_months = [6,7,8]\n",
        "#summer_missing_data_threshold = 0.90 * (30+31+31)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f6872aff-2036-4015-8df3-03ca7b4ee76a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6872aff-2036-4015-8df3-03ca7b4ee76a",
        "outputId": "bf795bb9-c973-460d-a734-4f052e24b722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "site_info_df:   agency_cd   site_no                               station_nm site_tp_cd  \\\n",
            "0      USGS  13190500  SF BOISE RIVER AT ANDERSON RANCH DAM ID         ST   \n",
            "\n",
            "   lat_va  long_va  dec_lat_va  dec_long_va coord_meth_cd coord_acy_cd  ...  \\\n",
            "0  432037  1152839   43.343611    -115.4775             G            S  ...   \n",
            "\n",
            "  reliability_cd gw_file_cd  nat_aqfr_cd  aqfr_cd  aqfr_type_cd well_depth_va  \\\n",
            "0            NaN   NNNNNNNN          NaN      NaN           NaN           NaN   \n",
            "\n",
            "  hole_depth_va depth_src_cd  project_no                    geometry  \n",
            "0           NaN          NaN         NaN  POINT (-115.4775 43.34361)  \n",
            "\n",
            "[1 rows x 43 columns]\n",
            "station_nm: SF BOISE RIVER AT ANDERSON RANCH DAM ID\n",
            "train_month: [3, 4, 5, 6, 7, 8]\n",
            "df_cleaned:            tmean   site_no       Date  Days_Since_October_1st  00010_Mean  \\\n",
            "8918   -1.199000  13190500 2020-03-01                     151         4.0   \n",
            "8919   -1.367000  13190500 2020-03-02                     152         4.1   \n",
            "8920    3.940400  13190500 2020-03-03                     153         4.4   \n",
            "8921    2.841400  13190500 2020-03-04                     154         4.2   \n",
            "8922    3.875500  13190500 2020-03-05                     155         4.1   \n",
            "...          ...       ...        ...                     ...         ...   \n",
            "10558  17.757401  13190500 2024-08-27                     330         9.8   \n",
            "10559  13.613300  13190500 2024-08-28                     331         9.6   \n",
            "10560  14.822449  13190500 2024-08-29                     332         9.5   \n",
            "10561  18.287849  13190500 2024-08-30                     333         9.7   \n",
            "10562  22.055199  13190500 2024-08-31                     334         9.7   \n",
            "\n",
            "       00060_Mean  \n",
            "8918        305.0  \n",
            "8919        299.0  \n",
            "8920        302.0  \n",
            "8921        301.0  \n",
            "8922        295.0  \n",
            "...           ...  \n",
            "10558       563.0  \n",
            "10559       528.0  \n",
            "10560       529.0  \n",
            "10561       526.0  \n",
            "10562       526.0  \n",
            "\n",
            "[920 rows x 6 columns]\n",
            " df_cleaned.describe():             tmean                 Date  Days_Since_October_1st  00010_Mean  \\\n",
            "count  920.000000                  920              920.000000  920.000000   \n",
            "mean    12.770957  2022-05-31 16:48:00              242.500000    6.542174   \n",
            "min     -8.266300  2020-03-01 00:00:00              151.000000    3.400000   \n",
            "25%      5.592250  2021-04-15 18:00:00              196.750000    4.800000   \n",
            "50%     13.607650  2022-05-31 12:00:00              242.500000    6.100000   \n",
            "75%     20.683000  2023-07-16 06:00:00              288.250000    8.200000   \n",
            "max     27.730900  2024-08-31 00:00:00              334.000000   12.000000   \n",
            "std      8.652572                  NaN               53.144331    2.093101   \n",
            "\n",
            "        00060_Mean  \n",
            "count   920.000000  \n",
            "mean   1115.826087  \n",
            "min     267.000000  \n",
            "25%     322.000000  \n",
            "50%    1160.000000  \n",
            "75%    1380.000000  \n",
            "max    6390.000000  \n",
            "std     925.256824  \n",
            "tmean                     0\n",
            "site_no                   0\n",
            "Date                      0\n",
            "Days_Since_October_1st    0\n",
            "00010_Mean                0\n",
            "00060_Mean                0\n",
            "dtype: int64\n",
            "gaps          tmean   site_no       Date  Days_Since_October_1st  00010_Mean  \\\n",
            "9283  -3.77430  13190500 2021-03-01                     151         3.5   \n",
            "9648   6.26810  13190500 2022-03-01                     151         3.9   \n",
            "10013 -4.08060  13190500 2023-03-01                     151         4.0   \n",
            "10379  1.10605  13190500 2024-03-01                     151         4.8   \n",
            "\n",
            "       00060_Mean      Gap  \n",
            "9283        307.0 182 days  \n",
            "9648        309.0 182 days  \n",
            "10013       280.0 182 days  \n",
            "10379       300.0 183 days  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-3487914925.py:60: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'])\n"
          ]
        }
      ],
      "source": [
        "site_info = nwis.get_info(sites= model_site )\n",
        "site_info_df = pd.DataFrame( site_info[0] )\n",
        "print(\"site_info_df:\",site_info_df)\n",
        "print(\"station_nm:\",site_info_df['station_nm'][0])\n",
        "site_info_df[\"site_no\"]=site_info_df[\"site_no\"].astype(str)\n",
        "columns_to_save = ['site_no', 'station_nm','dec_lat_va', 'dec_long_va', 'drain_area_va', 'contrib_drain_area_va' ,   'alt_va']\n",
        "filtered_df = site_info_df[columns_to_save]\n",
        "\n",
        "parameterCode = [\"00010\",\"00060\"  ]\n",
        "dailyStreamtemp = nwis.get_dv(sites= model_site\n",
        "                              , parameterCd=parameterCode, start=startDate, end=endDate)\n",
        "dailyStreamtemp_df = pd.DataFrame( dailyStreamtemp[0] )\n",
        "\n",
        "dailyStreamtemp_df = dailyStreamtemp_df.reset_index()\n",
        "# Extracts Date, Month, and Year components from the datetime column.\n",
        "dailyStreamtemp_df['Date'] = dailyStreamtemp_df['datetime'].dt.date\n",
        "dailyStreamtemp_df['Month'] = dailyStreamtemp_df['datetime'].dt.month\n",
        "dailyStreamtemp_df['Year'] = dailyStreamtemp_df['datetime'].dt.year\n",
        "\n",
        "dailyStreamtemp_df = dailyStreamtemp_df[ ~( (dailyStreamtemp_df[\"site_no\"]==\"13310800\") & (dailyStreamtemp_df[\"Year\"] == (2015) ) ) ]\n",
        "\n",
        "shared_url = \"https://drive.google.com/file/d/1z9w4rk21CCbbuOjwsru1pgkiOsYgVX6h/view?usp=share_link\"\n",
        "file_id = shared_url.split('/d/')[1].split('/')[0]\n",
        "download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "prism_df = pd.read_csv(download_url)\n",
        "prism_df['date'] = pd.to_datetime( prism_df['date'])\n",
        "\n",
        "# https://www.tensorflow.org/tutorials/structured_data/time_series\n",
        "# https://www.scirp.org/journal/paperinformation?paperid=142149\n",
        "# https://etasr.com/index.php/ETASR/article/view/10595\n",
        "\n",
        "def days_since_october_first(date):\n",
        "    october_first = pd.Timestamp(year=date.year, month=10, day=1)\n",
        "    days_difference = (date - october_first).days\n",
        "    return days_difference if days_difference >= 0 else days_difference + 365\n",
        "\n",
        "prism_df['Days_Since_October_1st'] =  prism_df['date'].apply(days_since_october_first)\n",
        "\n",
        "prism_df[\"site_no\"] =prism_df[\"site_no\"].astype(str)\n",
        "# Add a leading 0 to strings with exactly 7 characters\n",
        "prism_df['site_no'] = prism_df['site_no'].apply(lambda x: '0' + x if len(x) == 7 else x)\n",
        "prism_df[\"site_no\"] =prism_df[\"site_no\"].astype(str)\n",
        "\n",
        "prism_df['Date'] = prism_df['date'].dt.date\n",
        "\n",
        "prism_df = prism_df[['tmean' , \"site_no\", 'Date','Days_Since_October_1st'\n",
        " ]]\n",
        "\n",
        "dailyStreamtemp_df = dailyStreamtemp_df[[    'Date',       'site_no',  '00010_Mean', '00060_Mean'\n",
        "   ]]\n",
        "\n",
        "result = pd.merge(prism_df, dailyStreamtemp_df, on=['Date','site_no'], how='inner')\n",
        "\n",
        "# Count the number of NaN values in each column\n",
        "na_count = result.isna().sum()\n",
        "\n",
        "# Drop rows with any NaN values\n",
        "df_cleaned = result.dropna()\n",
        "\n",
        "df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'])\n",
        "\n",
        "train_month =  list(range( 3 , 8+1 ))\n",
        "\n",
        "print(\"train_month:\", train_month)\n",
        "\n",
        "df_cleaned= df_cleaned[ df_cleaned['Date'].dt.month.isin( train_month )]\n",
        "\n",
        "print(\"df_cleaned:\",df_cleaned)\n",
        "\n",
        "print(\" df_cleaned.describe():\",df_cleaned.describe())\n",
        "\n",
        "# Count the number of NaN values in each column\n",
        "na_count = df_cleaned.isna().sum()\n",
        "\n",
        "print(na_count)\n",
        "\n",
        "# gap\n",
        "\n",
        "# Calculate time difference between consecutive dates\n",
        "df_cleaned['Gap'] = df_cleaned['Date'].diff()\n",
        "\n",
        "# Filter rows where the gap is more than expected (e.g., > 1 day)\n",
        "expected_freq = pd.Timedelta(days=1)\n",
        "gaps = df_cleaned[df_cleaned['Gap'] > expected_freq]\n",
        "\n",
        "print(\"gaps\",gaps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d9e557a7-1608-4108-953a-59f2e4812f02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9e557a7-1608-4108-953a-59f2e4812f02",
        "outputId": "2b2027d9-6941-46bb-f764-7f2311f9cc1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(920, 7)\n",
            "(920, 7)\n",
            "\n",
            "DataFrame after Normalization Head:\n",
            "          tmean   site_no       Date  Days_Since_October_1st  00010_Mean  \\\n",
            "10558  0.722937  13190500 2024-08-27                0.978142    0.744186   \n",
            "10559  0.607814  13190500 2024-08-28                0.983607    0.720930   \n",
            "10560  0.641404  13190500 2024-08-29                0.989071    0.709302   \n",
            "10561  0.737673  13190500 2024-08-30                0.994536    0.732558   \n",
            "10562  0.842329  13190500 2024-08-31                1.000000    0.732558   \n",
            "\n",
            "       00060_Mean    Gap  \n",
            "10558    0.048342 1 days  \n",
            "10559    0.042626 1 days  \n",
            "10560    0.042789 1 days  \n",
            "10561    0.042300 1 days  \n",
            "10562    0.042300 1 days  \n"
          ]
        }
      ],
      "source": [
        "# --- 2. Preprocessing ---\n",
        "# Select features and target\n",
        "features = ['tmean',  '00060_Mean' ,\"Days_Since_October_1st\"]\n",
        "target = '00010_Mean'\n",
        "# Normalize the data\n",
        "# It's crucial to normalize all input features and the target variable for LSTMs.\n",
        "# We'll use a separate scaler for the target 'y' to easily inverse transform predictions.\n",
        "#  the minimum of feature is made equal to zero and the maximum of feature equal to one.\n",
        "scaler_features = MinMaxScaler(feature_range=(0, 1)) # other scalers like StandardScaler (Z-score normalization) might be more appropriate\n",
        "scaler_target = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "print(df_cleaned.shape)\n",
        "df = df_cleaned.copy()\n",
        "print(df.shape)\n",
        "# Fit and transform features\n",
        "df[features] = scaler_features.fit_transform(df[features])\n",
        "\n",
        "# Fit and transform target\n",
        "# Reshape for scaler (expects 2D array)\n",
        "df[target] = scaler_target.fit_transform(df[target].values.reshape(-1, 1))\n",
        "print(\"\\nDataFrame after Normalization Head:\")\n",
        "print(df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f1ff2931-1e64-4e59-be1f-6ac50a1dd748",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1ff2931-1e64-4e59-be1f-6ac50a1dd748",
        "outputId": "1562ff5a-d0ad-4177-e9a5-1105d9426b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_np: [[0.19632916 0.00620611 0.         0.06976744]\n",
            " [0.19166214 0.0052262  0.00546448 0.08139535]\n",
            " [0.33910138 0.00571615 0.01092896 0.11627907]\n",
            " ...\n",
            " [0.64140402 0.04278948 0.98907104 0.70930233]\n",
            " [0.73767264 0.04229953 0.99453552 0.73255814]\n",
            " [0.84232937 0.04229953 1.         0.73255814]]\n",
            "X [[[0.19632916 0.00620611 0.        ]\n",
            "  [0.19166214 0.0052262  0.00546448]\n",
            "  [0.33910138 0.00571615 0.01092896]\n",
            "  ...\n",
            "  [0.28569722 0.00636943 0.03825137]\n",
            "  [0.28644451 0.00620611 0.04371585]\n",
            "  [0.32450302 0.00555283 0.04918033]]\n",
            "\n",
            " [[0.19166214 0.0052262  0.00546448]\n",
            "  [0.33910138 0.00571615 0.01092896]\n",
            "  [0.30857123 0.00555283 0.01639344]\n",
            "  ...\n",
            "  [0.28644451 0.00620611 0.04371585]\n",
            "  [0.32450302 0.00555283 0.04918033]\n",
            "  [0.33893748 0.00555283 0.05464481]]\n",
            "\n",
            " [[0.33910138 0.00571615 0.01092896]\n",
            "  [0.30857123 0.00555283 0.01639344]\n",
            "  [0.33729846 0.00457292 0.02185792]\n",
            "  ...\n",
            "  [0.32450302 0.00555283 0.04918033]\n",
            "  [0.33893748 0.00555283 0.05464481]\n",
            "  [0.25415311 0.00653275 0.06010929]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.79489517 0.14910991 0.93989071]\n",
            "  [0.73937975 0.1507431  0.94535519]\n",
            "  [0.80469451 0.15237629 0.95081967]\n",
            "  ...\n",
            "  [0.7229368  0.04834232 0.97814208]\n",
            "  [0.60781396 0.04262616 0.98360656]\n",
            "  [0.64140402 0.04278948 0.98907104]]\n",
            "\n",
            " [[0.73937975 0.1507431  0.94535519]\n",
            "  [0.80469451 0.15237629 0.95081967]\n",
            "  [0.7275566  0.15237629 0.95628415]\n",
            "  ...\n",
            "  [0.60781396 0.04262616 0.98360656]\n",
            "  [0.64140402 0.04278948 0.98907104]\n",
            "  [0.73767264 0.04229953 0.99453552]]\n",
            "\n",
            " [[0.80469451 0.15237629 0.95081967]\n",
            "  [0.7275566  0.15237629 0.95628415]\n",
            "  [0.52016685 0.15237629 0.96174863]\n",
            "  ...\n",
            "  [0.64140402 0.04278948 0.98907104]\n",
            "  [0.73767264 0.04229953 0.99453552]\n",
            "  [0.84232937 0.04229953 1.        ]]]\n",
            "First 4 Y elements: [0.10465116 0.11627907 0.10465116 0.08139535]\n",
            "Last 4 Y elements: [0.72093023 0.70930233 0.73255814 0.73255814]\n",
            "\n",
            "Shape of X (samples, timesteps, features): (911, 10, 3)\n",
            "Shape of Y (samples, target_value): (911,)\n"
          ]
        }
      ],
      "source": [
        "# --- 3. Create Sequences for LSTM ---\n",
        "# LSTMs require data in a 3D format: (samples, timesteps, features)\n",
        "# 'timesteps' (also known as look_back) determines how many previous time steps\n",
        "# the LSTM will consider to predict the next value.\n",
        "\n",
        "look_back =  9 # You can adjust this based on your data's seasonality/dependencies\n",
        "\n",
        "def create_sequences(data, look_back, features_cols, target_col):\n",
        "    X, Y = [], []\n",
        "    # Ensure data is a numpy array for efficient indexing\n",
        "    data_np = data[features_cols + [target_col]].values # include target for sequence alignment\n",
        "    print(\"data_np:\",data_np)\n",
        "    # Features are the first 'num_features' columns, target is the last column.\n",
        "    num_features = len(features_cols)\n",
        "\n",
        "    for i in range(len(data_np) - look_back):\n",
        "        # X: look_back historical features (x1, x2)\n",
        "        X.append(data_np[i:(i + look_back +1), :num_features]) # (i + look_back +1) will include the feature of the day of the target\n",
        "        # Y: the 'y' value at the current time step (i + look_back)\n",
        "        Y.append(data_np[i + look_back, num_features]) # Target is the last column\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "X, Y = create_sequences(df, look_back, features, target)\n",
        "\n",
        "print(\"X\", X) # did I miss today's X?\n",
        "\n",
        "# Print first 4 elements\n",
        "print(\"First 4 Y elements:\", Y[:4])\n",
        "\n",
        "# Print last 4 elements\n",
        "print(\"Last 4 Y elements:\", Y[-4:])\n",
        "\n",
        "print(f\"\\nShape of X (samples, timesteps, features): {X.shape}\")\n",
        "print(f\"Shape of Y (samples, target_value): {Y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0896b472-1e5f-4483-9414-59aa2e7eb733",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0896b472-1e5f-4483-9414-59aa2e7eb733",
        "outputId": "b75483eb-8e2d-416d-de97-0c12e4bc008c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 728\n",
            "Test samples: 183\n",
            " Y Train samples: 728\n",
            "Y Test samples: 183\n"
          ]
        }
      ],
      "source": [
        "# --- 4. Train-Test Split (Time Series Split) ---\n",
        "# It's crucial to split time series data chronologically to avoid data leakage.\n",
        "train_size = int(len(X) * 0.8) # e.g., 80% for training, 20% for testing\n",
        "X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
        "Y_train, Y_test = Y[0:train_size], Y[train_size:len(Y)]\n",
        "\n",
        "print(f\"Train samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "print(f\" Y Train samples: {len(Y_train)}\")\n",
        "print(f\"Y Test samples: {len(Y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fa97f985-9db8-4695-b531-a8b13691e4b2",
      "metadata": {
        "id": "fa97f985-9db8-4695-b531-a8b13691e4b2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "optimizer='adam'\n",
        "\n",
        "def create_model( h1,   d1 , h2, d2):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units= h1, return_sequences=True , input_shape=(look_back, len(features))))\n",
        "    model.add(Dropout(  d1 ))  # Dropout to prevent overfitting\n",
        "    model.add(LSTM(units=h2, return_sequences=False))  # Last LSTM layer\n",
        "    model.add(Dropout(d2))\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "07aa5557-6dff-4f5d-8a52-345870996e5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07aa5557-6dff-4f5d-8a52-345870996e5f",
        "outputId": "0e7ef60b-b42b-4bc4-bbf7-502727b1668b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs'])\n",
            "model: KerasRegressor(\n",
            "\tmodel=<function create_model at 0x7cb9e1431c60>\n",
            "\tbuild_fn=None\n",
            "\twarm_start=False\n",
            "\trandom_state=None\n",
            "\toptimizer=rmsprop\n",
            "\tloss=None\n",
            "\tmetrics=None\n",
            "\tbatch_size=10\n",
            "\tvalidation_batch_size=None\n",
            "\tverbose=0\n",
            "\tcallbacks=[<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7cb9e0622310>]\n",
            "\tvalidation_split=0.0\n",
            "\tshuffle=True\n",
            "\trun_eagerly=False\n",
            "\tepochs=100\n",
            ")\n",
            "{'model__h1': [2, 4], 'model__d1': [0.0, 0.1], 'model__h2': [2, 4], 'model__d2': [0.0, 0.1]}\n",
            "GridSearchCV(cv=3,\n",
            "             estimator=KerasRegressor(batch_size=10, callbacks=[<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7cb9e0622310>], epochs=100, model=<function create_model at 0x7cb9e1431c60>, verbose=0),\n",
            "             n_jobs=-1,\n",
            "             param_grid={'model__d1': [0.0, 0.1], 'model__d2': [0.0, 0.1],\n",
            "                         'model__h1': [2, 4], 'model__h2': [2, 4]})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid_result: GridSearchCV(cv=3,\n",
            "             estimator=KerasRegressor(batch_size=10, callbacks=[<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7cb9e0622310>], epochs=100, model=<function create_model at 0x7cb9e1431c60>, verbose=0),\n",
            "             n_jobs=-1,\n",
            "             param_grid={'model__d1': [0.0, 0.1], 'model__d2': [0.0, 0.1],\n",
            "                         'model__h1': [2, 4], 'model__h2': [2, 4]})\n",
            "Best: 0.694115 using {'model__d1': 0.0, 'model__d2': 0.0, 'model__h1': 2, 'model__h2': 4}\n",
            "0.676477 (0.181164) with: {'model__d1': 0.0, 'model__d2': 0.0, 'model__h1': 2, 'model__h2': 2}\n",
            "0.694115 (0.146836) with: {'model__d1': 0.0, 'model__d2': 0.0, 'model__h1': 2, 'model__h2': 4}\n",
            "0.662665 (0.206259) with: {'model__d1': 0.0, 'model__d2': 0.0, 'model__h1': 4, 'model__h2': 2}\n",
            "0.648709 (0.224408) with: {'model__d1': 0.0, 'model__d2': 0.0, 'model__h1': 4, 'model__h2': 4}\n",
            "0.650154 (0.171417) with: {'model__d1': 0.0, 'model__d2': 0.1, 'model__h1': 2, 'model__h2': 2}\n",
            "0.651165 (0.200850) with: {'model__d1': 0.0, 'model__d2': 0.1, 'model__h1': 2, 'model__h2': 4}\n",
            "0.637509 (0.207412) with: {'model__d1': 0.0, 'model__d2': 0.1, 'model__h1': 4, 'model__h2': 2}\n",
            "0.649969 (0.244291) with: {'model__d1': 0.0, 'model__d2': 0.1, 'model__h1': 4, 'model__h2': 4}\n",
            "0.646275 (0.207139) with: {'model__d1': 0.1, 'model__d2': 0.0, 'model__h1': 2, 'model__h2': 2}\n",
            "0.650427 (0.198237) with: {'model__d1': 0.1, 'model__d2': 0.0, 'model__h1': 2, 'model__h2': 4}\n",
            "0.602532 (0.193761) with: {'model__d1': 0.1, 'model__d2': 0.0, 'model__h1': 4, 'model__h2': 2}\n",
            "0.663317 (0.199054) with: {'model__d1': 0.1, 'model__d2': 0.0, 'model__h1': 4, 'model__h2': 4}\n",
            "0.649990 (0.158159) with: {'model__d1': 0.1, 'model__d2': 0.1, 'model__h1': 2, 'model__h2': 2}\n",
            "0.656794 (0.175317) with: {'model__d1': 0.1, 'model__d2': 0.1, 'model__h1': 2, 'model__h2': 4}\n",
            "0.670022 (0.149072) with: {'model__d1': 0.1, 'model__d2': 0.1, 'model__h1': 4, 'model__h2': 2}\n",
            "0.671296 (0.176492) with: {'model__d1': 0.1, 'model__d2': 0.1, 'model__h1': 4, 'model__h2': 4}\n"
          ]
        }
      ],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True) #Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
        "\n",
        "# create model\n",
        "model = KerasRegressor(model=create_model\n",
        "                       , epochs= 100 # max epochs\n",
        "                       , callbacks=[early_stop]\n",
        "                       , batch_size=10, verbose=0)\n",
        "print(model.get_params().keys())\n",
        "print(\"model:\",model)\n",
        "# define the grid search parameters\n",
        "h1 = [ 2,4  ]\n",
        "h2 = [ 2,4  ]\n",
        "d1 = [0.0, 0.1 ]\n",
        "d2 = [0.0, 0.1 ]\n",
        "\n",
        "param_grid = dict( model__h1= h1 ,model__d1= d1, model__h2=h2 , model__d2=d2)\n",
        "print(param_grid)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "print(grid)\n",
        "grid_result = grid.fit(X_train, Y_train)\n",
        "print(\"grid_result:\",grid_result)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Make Predictions ---\n",
        "# Make predictions on the test set\n",
        "best_params= grid_result.best_params_\n",
        "\n",
        "print(\"best_params:\",best_params)\n",
        "\n",
        "#print(\"best_params:\",best_params.keys() )\n",
        "\n",
        "#print(\"best_params:\",best_params['model__d1'] )\n",
        "\n",
        "best_model = create_model(  best_params['model__h1'], best_params['model__d1'], best_params['model__h2'], best_params['model__d2']    )\n",
        "\n",
        "print(early_stop)\n",
        "\n",
        "#best_model = create_model(**{k: best_params[k] for k in ['model__h1', 'model__d1', 'model__h2', 'model__d2' ]})\n",
        "best_model.fit(X_train, Y_train, epochs=100 # best_params['epochs']\n",
        "               , callbacks=[early_stop]\n",
        "               #, batch_size=best_params['batch_size']\n",
        "               )\n",
        "\n",
        "Y_pred_scaled = best_model.predict(X_test)\n",
        "print(f\"\\nShape of Y_pred_scaled: {Y_pred_scaled.shape}\")\n",
        "print(f\"Shape of Y_test: {Y_test.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "\n",
        "# Inverse transform the predictions and actual values to the original scale\n",
        "Y_pred = scaler_target.inverse_transform(Y_pred_scaled)\n",
        "Y_test_original = scaler_target.inverse_transform(Y_test.reshape(-1, 1))\n",
        "\n",
        "r2 = r2_score( Y_test_original ,  Y_pred )\n",
        "\n",
        "# Calculate RMSE\n",
        "all_rmse = np.sqrt(mean_squared_error(Y_test_original, Y_pred))\n",
        "print(f\"Test RMSE: {all_rmse:.4f}\")\n",
        "\n",
        "bias =np.mean( Y_pred- Y_test_original)\n",
        "print(f\"Test bias: { bias:.4f}\")\n",
        "\n",
        "# KGE calculation using hydroeval\n",
        "# Note: hydroeval's kge function returns KGE, r, alpha, beta by default\n",
        "# kge_value, r_comp, alpha_comp, beta_comp = he.kge( Y_pred , Y_test_original)\n",
        "#print( kge_value)\n",
        "\n",
        "std_ratio = np.std( Y_pred ) / np.std( Y_test_original ) # standard deviation ratio\n",
        "correlation = np.corrcoef( Y_pred.flatten() ,  Y_test_original.flatten() )[0, 1]\n",
        "print(\"correlation\", correlation)\n",
        "\n",
        "print(np.std(Y_pred))\n",
        "print(np.std(Y_test_original))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BivEaA6cvWg-",
        "outputId": "abff763a-e8a4-4fe4-d9c0-7601de83ce69"
      },
      "id": "BivEaA6cvWg-",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_params: {'model__d1': 0.0, 'model__d2': 0.0, 'model__h1': 2, 'model__h2': 4}\n",
            "<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7cb9e0622310>\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.2272\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1242\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0663\n",
            "Epoch 4/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0457\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0430\n",
            "Epoch 6/100\n",
            "\u001b[1m19/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0394"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0402\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0373\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0344\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0313\n",
            "Epoch 10/100\n",
            "\u001b[1m13/23\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0261"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0281\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0251\n",
            "Epoch 12/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0223\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0200\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0182\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0169\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0160\n",
            "Epoch 17/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0155\n",
            "Epoch 18/100\n",
            "\u001b[1m13/23\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0136"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0151\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0149\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0147\n",
            "Epoch 21/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0146\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0145\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0144\n",
            "Epoch 24/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0143\n",
            "Epoch 25/100\n",
            "\u001b[1m13/23\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0127"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0142\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0141\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0141\n",
            "Epoch 28/100\n",
            "\u001b[1m20/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0136"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0140\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0139\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0139\n",
            "Epoch 31/100\n",
            "\u001b[1m10/23\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0114"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0138\n",
            "Epoch 32/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0137\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0137\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0136\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0136\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0135\n",
            "Epoch 37/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0135\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0134\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0134\n",
            "Epoch 40/100\n",
            "\u001b[1m 5/23\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0090"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0133\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0133\n",
            "Epoch 42/100\n",
            "\u001b[1m19/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0127"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0132\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0132\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0131\n",
            "Epoch 45/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0131\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0130\n",
            "Epoch 47/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0130\n",
            "Epoch 48/100\n",
            "\u001b[1m 7/23\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0096 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0129\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0129\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0128\n",
            "Epoch 51/100\n",
            "\u001b[1m14/23\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0117"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0128\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0128\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0127\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0127\n",
            "Epoch 55/100\n",
            "\u001b[1m 9/23\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0103"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0126\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0126\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0126\n",
            "Epoch 58/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0125\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0125\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0124\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0124\n",
            "Epoch 62/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0124\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0123\n",
            "Epoch 64/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0123\n",
            "Epoch 65/100\n",
            "\u001b[1m14/23\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0113"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0123\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0122\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0122\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0122\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0121\n",
            "Epoch 70/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0121\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0121\n",
            "Epoch 72/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0120\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0120\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0120\n",
            "Epoch 75/100\n",
            "\u001b[1m18/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0114"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0119\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0119\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0119\n",
            "Epoch 78/100\n",
            "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - loss: 0.0081"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0118\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0118\n",
            "Epoch 80/100\n",
            "\u001b[1m13/23\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0118\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0117\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0117\n",
            "Epoch 83/100\n",
            "\u001b[1m13/23\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0106 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0117\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0117\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0116\n",
            "Epoch 86/100\n",
            "\u001b[1m 8/23\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0093"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0116\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0116\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0115\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0115\n",
            "Epoch 90/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0115\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0115\n",
            "Epoch 92/100\n",
            "\u001b[1m19/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0110"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0114\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0114\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0114\n",
            "Epoch 95/100\n",
            "\u001b[1m19/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0110"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0113\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0113\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0113\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0113\n",
            "Epoch 99/100\n",
            "\u001b[1m11/23\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0099"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0112\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step\n",
            "\n",
            "Shape of Y_pred_scaled: (183, 1)\n",
            "Shape of Y_test: (183,)\n",
            "Shape of X_test: (183, 10, 3)\n",
            "Test RMSE: 1.0242\n",
            "Test bias: -0.0127\n",
            "correlation 0.8550473749794817\n",
            "1.9386381\n",
            "1.853233231187897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec64ad7-fe01-429f-a9ab-1f1e588ac11d",
      "metadata": {
        "id": "eec64ad7-fe01-429f-a9ab-1f1e588ac11d"
      },
      "outputs": [],
      "source": [
        "from numpy import array\n",
        "from permetrics.regression import RegressionMetric\n",
        "\n",
        "## For 1-D array\n",
        "y_true = array([3, -0.5, 2, 7])\n",
        "y_pred = array([2.5, 0.0, 2, 8])\n",
        "\n",
        "evaluator = RegressionMetric(y_true, y_pred)\n",
        "print(evaluator.nash_sutcliffe_efficiency())\n",
        "\n",
        "## For > 1-D array\n",
        "y_true = array([[0.5, 1], [-1, 1], [7, -6]])\n",
        "y_pred = array([[0, 2], [-1, 2], [8, -5]])\n",
        "\n",
        "evaluator = RegressionMetric(y_true, y_pred)\n",
        "print(evaluator.NSE(multi_output=\"raw_values\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}